# src/visualize_advanced/win_prediction_analysis.py

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.font_manager as fm

# ğŸŒŸ ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_PATH = "data/opscore_results.csv"
VISUALIZATION_PATH = r"C:\Users\user\PycharmProjects\Last_LOL_Project\visualizations"

# ğŸŒŸ í•œê¸€ í°íŠ¸ (Windows 100% ì•ˆì •)
KOREAN_FONT_NAME = 'Malgun Gothic'
plt.rcParams['font.family'] = KOREAN_FONT_NAME
plt.rcParams['axes.unicode_minus'] = False


# =======================================================
# [1] ë°ì´í„° ì¤€ë¹„ ë° ìŠ¹íŒ¨ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
# =======================================================

def prepare_data_and_predict():
    print("ğŸš€ STEP 7: ê¸°ì—¬ë„ ì ìˆ˜ ê¸°ë°˜ ìŠ¹íŒ¨ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œì‘...")

    # ğŸš¨ íŒŒì¼ ë¡œë“œ (opscore_results.csv ì‚¬ìš©)
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    data_path = os.path.join(base_dir, DATA_PATH)

    if not os.path.exists(data_path):
        print(f"âŒ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {DATA_PATH} ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    df_score = pd.read_csv(data_path)

    # ğŸŒŸğŸŒŸğŸŒŸ ì˜¤ë¥˜ í•´ê²° ë¡œì§: 'win' ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ì¬ì •ì˜ ğŸŒŸğŸŒŸğŸŒŸ
    if 'win' not in df_score.columns or df_score['win'].isnull().all():
        print("âš ï¸ 'win' ì»¬ëŸ¼ì´ ì—†ì–´, 'target_gold' ìµœëŒ€ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ìŠ¹íŒ¨ë¥¼ ì„ì‹œ ìƒì„±í•©ë‹ˆë‹¤.")

        # 1. ê° ë§¤ì¹˜ë³„ ìµœì¢… ëˆ„ì  ê³¨ë“œ (Max target_gold)ë¥¼ ê°€ì§„ íŒ€ ì°¾ê¸°
        df_score['max_gold_in_match'] = df_score.groupby('match_id')['target_gold'].transform('max')

        # 2. í•´ë‹¹ ë§¤ì¹˜ì—ì„œ Max Goldë¥¼ ê°€ì§„ íŒ€ì„ ìŠ¹ë¦¬(True)ë¡œ ì„¤ì •
        df_score['win'] = df_score['target_gold'] == df_score['max_gold_in_match']
    # ğŸŒŸğŸŒŸğŸŒŸ

    # 1. ê° ë§¤ì¹˜/íŒ€ë³„ ìµœì¢… ê¸°ì—¬ë„ ì ìˆ˜ í‰ê·  ë° ìŠ¹íŒ¨ ìƒíƒœ ì§‘ê³„
    df_match_summary = df_score.groupby(['match_id', 'team_id']).agg(
        avg_score=('final_score_norm', 'mean'),
        win=('win', 'first')
    ).reset_index()

    # 2. Match_IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ Team 100(Blue)ê³¼ Team 200(Red)ì˜ ì ìˆ˜ë¥¼ ì˜†ìœ¼ë¡œ í¼ì¹¨
    df_pivot = df_match_summary.pivot(
        index='match_id',
        columns='team_id',
        values=['avg_score', 'win']
    )

    # ì»¬ëŸ¼ ì •ë¦¬
    df_pivot.columns = ['_'.join(map(str, col)).strip() for col in df_pivot.columns.values]
    df_pivot = df_pivot.reset_index()

    # ìŠ¹íŒ¨ ì»¬ëŸ¼ ì„¤ì • (Team 100ì˜ ìŠ¹íŒ¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •)
    df_pivot['target_win'] = df_pivot['win_100'].astype(int)

    # ğŸš¨ ìµœì¢… í”¼ì²˜ X: Team 100ê³¼ Team 200ì˜ í‰ê·  ê¸°ì—¬ë„ ì ìˆ˜ë§Œ ì‚¬ìš©
    X = df_pivot[['avg_score_100', 'avg_score_200']]
    y = df_pivot['target_win']

    # 3. ëª¨ë¸ í•™ìŠµ
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    model = LogisticRegression(random_state=42)
    model.fit(X_train, y_train)

    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_pred_proba > 0.5).astype(int)

    accuracy = accuracy_score(y_test, y_pred)

    print(f"âœ”ï¸ Logistic Regression ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")
    print(f"   -> í…ŒìŠ¤íŠ¸ ì •í™•ë„ (Accuracy): {accuracy:.4f}")

    return y_test, y_pred, y_pred_proba, accuracy


# =======================================================
# [2] ROC Curve ì‹œê°í™”
# =======================================================

def plot_win_prediction_metrics(y_test, y_pred_proba, accuracy, save=True):
    """ROC Curveì™€ Confusion Matrixë¥¼ ì‹œê°í™”"""

    # 1. ROC Curve ê³„ì‚°
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    # 2. ì‹œê°í™” (2x1 Subplots)
    fig, ax = plt.subplots(1, 2, figsize=(14, 6))

    # A. ROC Curve
    ax[0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    ax[0].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')
    ax[0].set_xlim([0.0, 1.0])
    ax[0].set_ylim([0.0, 1.05])
    ax[0].set_xlabel('False Positive Rate (FPR)')
    ax[0].set_ylabel('True Positive Rate (TPR)')
    ax[0].set_title('A. ROC Curve for Win Prediction', fontsize=14)
    ax[0].legend(loc="lower right")

    # B. Confusion Matrix (ì •í™•ë„ ëŒ€ì‹  ì˜ˆì¸¡ ê²½í–¥ì„± í™•ì¸)
    cm = confusion_matrix(y_test, (y_pred_proba > 0.5).astype(int))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax[1])
    ax[1].set_xlabel('Predicted Label')
    ax[1].set_ylabel('True Label')
    ax[1].set_title(f'B. Confusion Matrix (Accuracy: {accuracy:.4f})', fontsize=14)
    ax[1].xaxis.set_ticklabels(['Loss (200 Win)', 'Win (100 Win)'])
    ax[1].yaxis.set_ticklabels(['Loss (200 Win)', 'Win (100 Win)'])

    fig.suptitle("Win Prediction Analysis using Final Contribution Score", fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.95])

    # 3. ì €ì¥
    if save:
        out_dir = os.path.join(VISUALIZATION_PATH, "win_prediction")
        os.makedirs(out_dir, exist_ok=True)
        path = os.path.join(out_dir, "win_prediction_analysis.png")
        plt.savefig(path, dpi=200)
        print(f"âœ” Saved Win Prediction Analysis: {path}")

    plt.show()
    plt.close()


if __name__ == "__main__":
    try:
        results = prepare_data_and_predict()
        if results is not None:
            y_test, y_pred, y_pred_proba, accuracy = results
            plot_win_prediction_metrics(y_test, y_pred_proba, accuracy, save=True)
            print("ğŸ‰ ìŠ¹íŒ¨ ì˜ˆì¸¡ ì‹œê°í™” ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ìµœì¢… ì‹œê°í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")