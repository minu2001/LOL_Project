from src.load_data import convert_json_to_parquet, get_parquet_paths
from src.feature_extract import extract_minute_features
from src.build_phase_datasets import build_phase_datasets
from src.model_training import train_all_models
from src.scoring import compute_opscore
from src.visualize import visualize_feature_importance, visualize_opscore_distribution


def main():

    print("ğŸ“Œ STEP 0) JSON â†’ Parquet ë³€í™˜")
    convert_json_to_parquet()

    print("ğŸ“Œ STEP 1) íŒŒì¼ ê²½ë¡œ ë¡œë“œ")
    match_paths, timeline_paths = get_parquet_paths()
    print(f"Matches = {len(match_paths)} | Timelines = {len(timeline_paths)}")

    print("ğŸ“Œ STEP 2) Minute Feature ì¶”ì¶œ")
    df_minute = extract_minute_features(match_paths, timeline_paths)

    print("ğŸ“Œ STEP 3) Phase Split")
    df_early, df_late, df_end = build_phase_datasets(df_minute)

    df_early.to_csv("data/phase_early.csv", index=False)
    df_late.to_csv("data/phase_late.csv", index=False)
    df_end.to_csv("data/phase_end.csv", index=False)

    print("ğŸ“Œ STEP 4) ëª¨ë¸ í•™ìŠµ")
    train_all_models(df_early, df_late, df_end)

    print("ğŸ“Œ STEP 5) OPScore ê³„ì‚°")
    df_score                                                   = compute_opscore(df_minute)
    df_score.to_csv("data/opscore_results.csv", index=False)

    print("ğŸ“Œ STEP 6) ì‹œê°í™”")
    visualize_feature_importance()
    visualize_opscore_distribution(df_score)

    print("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
